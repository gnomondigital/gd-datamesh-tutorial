## Table of Contents

1. [Introduction](#introduction)
2. [Creating a Pipeline](#creating-a-pipeline)
3. [Orchestrating with Airflow](#orchestrating-with-airflow)
4. [Creating an API](#creating-an-api)
5. [Deploying with GCP](#deploying-with-gcp)
6. [Connect with Us](#connect-with-us)

# gd-datamesh-tutorial

Welcome to the Data Mesh Tutorial project! This repository contains a comprehensive guide to implementing a data mesh architecture. The tutorial is divided into four main parts:

1. **Creating a Pipeline**
2. **Orchestrating with Airflow**
3. **Creating an API**
4. **Deploying with GCP**


## Introduction

In this tutorial, we will walk you through the steps to build a data mesh architecture. Each part of the tutorial focuses on a specific aspect of the data mesh, providing detailed instructions and examples.

## Creating a Pipeline

In this section, you will learn how to create a data pipeline. We will cover:

- Setting up the environment
- Extracting data from sources
- Transforming data
- Loading data into a data warehouse

## Orchestrating with Airflow

This section focuses on orchestrating your data pipeline using Apache Airflow. Topics include:

- Installing and configuring Airflow
- Creating DAGs (Directed Acyclic Graphs)
- Scheduling and monitoring workflows

## Creating an API

Learn how to create an API to expose your data. This part covers:

- Designing API endpoints
- Implementing CRUD operations

## Deploying with GCP

Finally, we will deploy our data mesh on Google Cloud Platform (GCP). This section includes:

- Deploying the API and data pipeline

## Connect with Us

- [LinkedIn](https://www.linkedin.com/company/gnomon-digital)
- [Medium](https://medium.com/gnomondigital)
- [Official Website](https://www.gnomondigital.com)